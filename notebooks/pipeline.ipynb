{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c852ec-25ac-4a93-8929-fc65f48e7f92",
   "metadata": {},
   "source": [
    "## Parse into beliefs\n",
    "\n",
    "Additional detail on the development of the belief parser may be found in [ICWSM_revisions2a.ipynb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f922c5-d95e-4cd9-b6ac-8b64309b3920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import allTokens\n",
    "from allTokens import abbr_dict, emoji_pattern\n",
    "\n",
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from spacy.language import Language\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from belief_extraction_spacy import add_to_pipe\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "488c3ab0-a35c-4b57-add8-6197900b9db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy==3.5.4 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (3.5.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (2.28.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (4.65.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (8.1.12)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (1.0.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (2.4.6)\n",
      "Requirement already satisfied: setuptools in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (44.0.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (1.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (2.0.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (6.3.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (0.3.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (3.0.12)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy==3.5.4) (0.10.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy==3.5.4) (4.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from jinja2->spacy==3.5.4) (2.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.4) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.4) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.4) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.4) (1.26.15)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.4) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.4) (0.1.1)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from typer<0.10.0,>=0.3.0->spacy==3.5.4) (7.1.2)\n",
      "Requirement already satisfied: en-core-web-lg==3.5.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl in /home/rkamath/C4_Labs/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from en-core-web-lg==3.5.0) (3.5.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.24.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: setuptools in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (44.0.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.12)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.3.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: jinja2 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.1.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rkamath/C4_Labs/lib/python3.8/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy==3.5.4\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594b2de4-66c4-4a6e-b9ee-c13d604ec670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4\n"
     ]
    }
   ],
   "source": [
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64edcd00-95b2-4504-8319-c8052600ac70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f741daf34f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load SpaCy model and add plugin to pipeline\n",
    "%run \"belief_extraction_spacy.py\"\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "# nlp = spacy.load('en_core_web_lg', disable=[\"ner\", \"lemmatizer\"])  # Disable unnecessary components\n",
    "add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c878e51d-88ff-4c4b-aec3-e2e9f332ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_texts(texts):\n",
    "    \"\"\"\n",
    "    Process texts with spaCy and extract relevant information for beliefs.\n",
    "    Returns a list of dictionaries with 'text' and 'beliefs'.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "    for doc in nlp.pipe(texts, batch_size=50):\n",
    "        for sent in doc.sents:\n",
    "            if hasattr(sent._, 'beliefs') and sent._.beliefs:\n",
    "                beliefs_info = [{'subject': b.subject, 'sentence': str(s)} for b in sent._.beliefs for s in doc.sents]\n",
    "                processed_data.append({'text': doc.text, 'beliefs': beliefs_info})\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "\n",
    "# def process_text_and_extract_beliefs(text):\n",
    "#     # Process the text with spaCy to create a Doc object\n",
    "#     doc = nlp(text)\n",
    "#     beliefs = []\n",
    "#     for sent in doc.sents:\n",
    "#         if hasattr(sent._, 'beliefs') and sent._.beliefs:\n",
    "#             beliefs.extend([(b.subject, str(s)) for b in sent._.beliefs for s in doc.sents])\n",
    "#     return beliefs\n",
    "\n",
    "\n",
    "# def extract_beliefs(texts):\n",
    "#     beliefs = []\n",
    "#     for doc in nlp.pipe(texts, batch_size=50):  # Use batch processing\n",
    "#         for sent in doc.sents:\n",
    "#             if sent._.beliefs:\n",
    "#                 beliefs.extend([(b.subject, str(s)) for b in sent._.beliefs for s in doc.sents])\n",
    "#     return belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d84046c5-abd1-4c40-8025-ef7816a753b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def further_processing(data):\n",
    "    # Placeholder for further processing, returns data as-is\n",
    "    return data\n",
    "\n",
    "# def worker_func(df_slice, column):\n",
    "#     # Apply the processing and extraction function to each text in the DataFrame slice\n",
    "#     df_slice[column] = df_slice[column].apply(process_text_and_extract_beliefs)\n",
    "#     return df_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7578c7dd-98e0-4ab8-bc3f-dcd185112ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_process(data, num_cores):\n",
    "    with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "        result = list(executor.map(further_processing, data))\n",
    "    return result\n",
    "\n",
    "# def parallel_apply(df, column, num_partitions, num_cores):\n",
    "#     df_split = np.array_split(df, num_partitions)\n",
    "#     with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "#         # Map the worker function across DataFrame slices\n",
    "#         results = list(executor.map(worker_func, df_split, [column]*len(df_split)))\n",
    "#     return pd.concat(results)\n",
    "\n",
    "# def parallel_apply(df, func, column, num_partitions, num_cores):\n",
    "#     df_split = np.array_split(df, num_partitions)\n",
    "#     pool = ProcessPoolExecutor(num_cores)\n",
    "#     # Use a wrapper function instead of a lambda for multiprocessing\n",
    "#     results = pool.map(apply_extract_beliefs_to_df, df_split, [func]*len(df_split), [column]*len(df_split))\n",
    "#     df = pd.concat(list(results))\n",
    "#     pool.shutdown()\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8147f890-67c5-41d6-965a-d3f681bbc3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_partitions = 10  # Number of partitions to split dataframe\n",
    "# num_cores = 4       # Number of cores on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68564b69-95b9-4ac1-8956-371473f755b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_DATA = \"../../../data/politics_cleaned\"\n",
    "file_path = f\"{L_DATA}/total_cleaned_tweets.feather\"\n",
    "deduped = pd.read_feather(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "315c0173-f641-413c-a2c2-6439701d6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_texts = deduped['cleanedText'].head(1000).tolist()\n",
    "processed_data = preprocess_texts(subset_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c35d5-35f7-4902-9134-da52f888cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = 4  # Adjust based on your machine\n",
    "parallel_results = parallel_process(processed_data, num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0905f9b-7dd8-4dc6-a7bf-85274eaf275c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "[E112] Pickling a span is not supported, because spans are only views of the parent Doc and can't exist on their own. A pickled span would always have to include its Doc and Vocab, which has practically no advantage over pickling the parent Doc directly. So instead of pickling the span, pickle the Doc it belongs to or use Span.as_doc to convert the span to a standalone Doc object.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 204, in _sendback_result\n    result_queue.put(_ResultItem(work_id, result=result,\n  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 362, in put\n    obj = _ForkingPickler.dumps(obj)\n  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"spacy/tokens/span.pyx\", line 206, in spacy.tokens.span.Span.__reduce__\nNotImplementedError: [E112] Pickling a span is not supported, because spans are only views of the parent Doc and can't exist on their own. A pickled span would always have to include its Doc and Vocab, which has practically no advantage over pickling the parent Doc directly. So instead of pickling the span, pickle the Doc it belongs to or use Span.as_doc to convert the span to a standalone Doc object.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m deduped[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeliefs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeduped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcleanedText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_partitions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_cores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# deduped['beliefs'] = parallel_apply(deduped, extract_beliefs, 'cleanedText', num_partitions, num_cores)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(df, column, num_partitions, num_cores)\u001b[0m\n\u001b[1;32m      2\u001b[0m df_split \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_split(df, num_partitions)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mnum_cores) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Map the worker function across DataFrame slices\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworker_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_split\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(results)\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/process.py:484\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    479\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    485\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: [E112] Pickling a span is not supported, because spans are only views of the parent Doc and can't exist on their own. A pickled span would always have to include its Doc and Vocab, which has practically no advantage over pickling the parent Doc directly. So instead of pickling the span, pickle the Doc it belongs to or use Span.as_doc to convert the span to a standalone Doc object."
     ]
    }
   ],
   "source": [
    "# deduped['beliefs'] = parallel_apply(deduped, 'cleanedText', num_partitions, num_cores)\n",
    "# deduped['beliefs'] = parallel_apply(deduped, extract_beliefs, 'cleanedText', num_partitions, num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a74d8d1-6015-4762-aa5a-98a65e917e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling\n",
    "labeled_beliefs = deduped.explode('beliefs').dropna(subset=['beliefs'])\n",
    "labeled_beliefs[['subject', 'sentence']] = pd.DataFrame(labeled_beliefs['beliefs'].tolist(), index=labeled_beliefs.index)\n",
    "labeled_beliefs = labeled_beliefs.reset_index(drop=True)\n",
    "labeled_beliefs['sentence_idx'] = labeled_beliefs.groupby('tweet_hash').cumcount()\n",
    "\n",
    "# Save and load data\n",
    "labeled_beliefs.to_feather(f'{L_DATA}/english_cleaned_deduped_labeled_beliefs.feather')\n",
    "d = pd.read_feather(f'{G_DATA}/english_cleaned_deduped_labeled_beliefs.feather')\n",
    "print(d.subject.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25190350-3a42-4e66-ad90-f3c89b29dc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb068b5b-72c9-4416-ada9-5f37f322b0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52020b-66fa-4cb2-b4d0-0d0371c2f7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
